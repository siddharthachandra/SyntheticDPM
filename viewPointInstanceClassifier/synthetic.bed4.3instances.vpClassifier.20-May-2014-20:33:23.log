NUMLINES READ: 2280

parm = 

               c: 0.1000
             fct: 0.2000
        sizeRoot: [10 10]
         featDim: 32
            sbin: 8
          padHog: 2
    sanityChecks: 1
      rootLength: 3200
        sizeBBOX: [12 12]
               e: 1.0000e-03
      numSamples: 2280
        numViews: 4
    numInstances: 3
       dimension: 38400
        patterns: {1x2280 cell}
          labels: {1x2280 cell}
          lossFn: @loss_vp
       featureFn: @mypsi_vp
    constraintFn: @mvc_vp

There are 2280 training examples
Iter 1: .........*Reducing working set...done. (NumConst=1, SV=1, CEps=1.0000, QPEps=0.0000)
Iter 2: .........*Reducing working set...done. (NumConst=2, SV=1, CEps=1.0483, QPEps=0.3416)
Iter 3: .........*Reducing working set...done. (NumConst=3, SV=3, CEps=0.3416, QPEps=0.0013)
Iter 4: .........*Reducing working set...done. (NumConst=4, SV=4, CEps=0.2308, QPEps=0.0012)
Iter 5: .........*Reducing working set...done. (NumConst=5, SV=5, CEps=0.1396, QPEps=0.0011)
Iter 6: .........*Reducing working set...done. (NumConst=6, SV=6, CEps=0.1032, QPEps=0.0014)
Iter 7: .........*Reducing working set...done. (NumConst=7, SV=7, CEps=0.0712, QPEps=0.0015)
Iter 8: .........*Reducing working set...done. (NumConst=8, SV=8, CEps=0.0513, QPEps=0.0008)
Iter 9: .........*Reducing working set...done. (NumConst=9, SV=9, CEps=0.0417, QPEps=0.0003)
Iter 10: .........*Reducing working set...done. (NumConst=10, SV=9, CEps=0.0272, QPEps=0.0000)
Iter 11: .........*Reducing working set...done. (NumConst=11, SV=10, CEps=0.0208, QPEps=0.0000)
Iter 12: .........*Reducing working set...done. (NumConst=12, SV=11, CEps=0.0173, QPEps=0.0057)
Iter 13: .........*Reducing working set...done. (NumConst=13, SV=12, CEps=0.0177, QPEps=0.0073)
Iter 14: .........*Reducing working set...done. (NumConst=14, SV=12, CEps=0.0152, QPEps=0.0061)
Iter 15: .........*Reducing working set...done. (NumConst=15, SV=12, CEps=0.0091, QPEps=0.0018)
Iter 16: .........*Reducing working set...done. (NumConst=16, SV=12, CEps=0.0093, QPEps=0.0020)
Iter 17: .........*Reducing working set...done. (NumConst=17, SV=11, CEps=0.0096, QPEps=0.0010)
Iter 18: .........*Reducing working set...done. (NumConst=18, SV=10, CEps=0.0069, QPEps=0.0000)
Iter 19: .........*Reducing working set...done. (NumConst=19, SV=11, CEps=0.0060, QPEps=0.0025)
Iter 20: .........*Reducing working set...done. (NumConst=20, SV=11, CEps=0.0073, QPEps=0.0010)
Iter 21: .........*Reducing working set...done. (NumConst=21, SV=12, CEps=0.0058, QPEps=0.0008)
Iter 22: .........*Reducing working set...done. (NumConst=22, SV=13, CEps=0.0040, QPEps=0.0014)
Iter 23: .........*Reducing working set...done. (NumConst=23, SV=13, CEps=0.0050, QPEps=0.0017)
Iter 24: .........*Reducing working set...done. (NumConst=24, SV=13, CEps=0.0039, QPEps=0.0019)
Iter 25: .........*Reducing working set...done. (NumConst=25, SV=13, CEps=0.0041, QPEps=0.0018)
Iter 26: .........*Reducing working set...done. (NumConst=26, SV=13, CEps=0.0032, QPEps=0.0006)
Iter 27: .........*Reducing working set...done. (NumConst=27, SV=12, CEps=0.0031, QPEps=0.0011)
Iter 28: .........*Reducing working set...done. (NumConst=28, SV=13, CEps=0.0025, QPEps=0.0004)
Iter 29: .........*Reducing working set...done. (NumConst=29, SV=14, CEps=0.0022, QPEps=0.0009)
Iter 30: .........*Reducing working set...done. (NumConst=30, SV=14, CEps=0.0022, QPEps=0.0011)
Iter 31: .........*Reducing working set...done. (NumConst=31, SV=13, CEps=0.0025, QPEps=0.0006)
Iter 32: .........*Reducing working set...done. (NumConst=32, SV=13, CEps=0.0015, QPEps=0.0003)
Iter 33: .........*Reducing working set...done. (NumConst=33, SV=12, CEps=0.0015, QPEps=0.0005)
Iter 34: .........*Reducing working set...done. (NumConst=34, SV=12, CEps=0.0014, QPEps=0.0002)
Iter 35: .........*Reducing working set...done. (NumConst=35, SV=14, CEps=0.0013, QPEps=0.0004)
Iter 36: .........*Reducing working set...done. (NumConst=36, SV=12, CEps=0.0013, QPEps=0.0006)
Iter 37: .........*Reducing working set...done. (NumConst=37, SV=14, CEps=0.0012, QPEps=0.0006)
Iter 38: .........(NumConst=37, SV=14, CEps=0.0009, QPEps=0.0006)
Final epsilon on KKT-Conditions: 0.00094
Upper bound on duality gap: 0.00010
Dual objective value: dval=0.09378
Primal objective value: pval=0.09388
Total number of constraints in final working set: 37 (of 37)
Number of iterations: 38
Number of calls to 'find_most_violated_constraint': 86640
Number of SV: 14 
Norm of weight vector: |w|=0.11151
Value of slack variable (on working set): xi=0.87580
Value of slack variable (global): xi=0.87663
Norm of longest difference vector: ||Psi(x,y)-Psi(x,ybar)||=3.88550
Runtime in cpu-seconds: 78.83 (0.04% for QP, 0.11% for kernel, 53.76% for Argmax, 42.12% for Psi, 1.24% for init, 0.00% for cache update, 0.00% for cache const, 0.00% for cache add (incl. 0.00% for sum))
Losses: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Average Prediction Loss per Sample: 0.000438596
